"""LanceDB database writer for guides and chunks with auto-embedding."""

import hashlib
import uuid
from datetime import UTC, datetime
from pathlib import Path
from typing import TYPE_CHECKING, Any

import lancedb

from mcp_canon.ingestion.chunker import Chunk
from mcp_canon.ingestion.summarizer import extract_headings, extractive_summary_from_chunks
from mcp_canon.schemas.database import (
    ChunkSchema,
    DatabaseMetadata,
    GuideSchema,
)
from mcp_canon.schemas.frontmatter import GuideFrontmatter

if TYPE_CHECKING:
    from lancedb.table import Table


def compute_content_hash(content: str) -> str:
    """Compute SHA256 hash of content for change detection."""
    return hashlib.sha256(content.encode("utf-8")).hexdigest()


class DatabaseWriter:
    """Write guides and chunks to LanceDB using LanceModel schemas with auto-embedding."""

    def __init__(self, db_path: str | Path):
        """
        Initialize database writer.

        Args:
            db_path: Path to LanceDB database directory
        """
        self.db_path = Path(db_path)
        self._db: lancedb.DBConnection | None = None

    @property
    def db(self) -> lancedb.DBConnection:
        """Lazy-connect to database."""
        if self._db is None:
            self._db = lancedb.connect(str(self.db_path))
        return self._db

    def _get_or_create_table(
        self,
        table_name: str,
        schema: type[GuideSchema] | type[ChunkSchema] | type[DatabaseMetadata],
    ) -> "Table":
        """Get existing table or create with schema."""
        if table_name in self.db.list_tables().tables:
            return self.db.open_table(table_name)
        return self.db.create_table(table_name, schema=schema)

    def initialize_database(self, library_path: str, preserve_existing: bool = False) -> None:
        """
        Initialize database with metadata table.

        Args:
            library_path: Path to source library
            preserve_existing: If True, preserve existing guides (append mode)
        """
        now = datetime.now(UTC).isoformat()

        # In append mode, preserve existing data
        if preserve_existing and "_metadata" in self.db.list_tables().tables:
            self.update_last_indexed()
            return

        metadata = DatabaseMetadata(
            created_at=now,
            last_indexed_at=now,
            library_path=library_path,
        )

        # Drop ALL tables for clean re-index (prevents stale schema conflicts)
        for table_name in ("guides", "chunks", "_metadata"):
            if table_name in self.db.list_tables().tables:
                self.db.drop_table(table_name)

        table = self.db.create_table("_metadata", schema=DatabaseMetadata)
        table.add([metadata])

    def get_existing_guides(self) -> dict[str, str]:
        """
        Get existing guides with their content hashes.

        Returns:
            Dict mapping guide_id to content_hash
        """
        if "guides" not in self.db.list_tables().tables:
            return {}

        table = self.db.open_table("guides")
        rows = table.search().select(["id", "content_hash"]).to_list()
        return {row["id"]: row["content_hash"] for row in rows}

    def delete_guide(self, guide_id: str) -> None:
        """Delete a guide and its chunks from the database."""
        # Sanitize guide_id to prevent injection
        safe_id = guide_id.replace("'", "''")

        if "guides" in self.db.list_tables().tables:
            guides_table = self.db.open_table("guides")
            guides_table.delete(f"id = '{safe_id}'")

        if "chunks" in self.db.list_tables().tables:
            chunks_table = self.db.open_table("chunks")
            chunks_table.delete(f"guide_id = '{safe_id}'")

    def write_guide(
        self,
        guide_id: str,
        namespace: str,
        frontmatter: GuideFrontmatter,
        content: str,
        file_path: str,
        chunks: list[Chunk],
    ) -> None:
        """
        Write a guide and its chunks to the database.

        Embeddings are auto-generated by LanceDB using the schema's VectorField.

        Args:
            guide_id: Guide ID (namespace/guide_name)
            namespace: Technology stack
            frontmatter: Parsed frontmatter
            content: Full guide content
            file_path: Path to INDEX.md
            chunks: List of content chunks
        """
        now = datetime.now(UTC).isoformat()
        content_hash = compute_content_hash(content)

        chunk_records: list[dict[str, Any]] = []
        for chunk in chunks:
            chunk_records.append(
                {
                    "id": str(uuid.uuid4()),
                    "guide_id": guide_id,
                    "namespace": namespace,
                    "tags": frontmatter.metadata.tags,
                    "heading": chunk.heading,
                    "heading_path": chunk.heading_path,
                    "content": chunk.content,
                    "chunk_index": chunk.chunk_index,
                    "char_count": chunk.char_count,
                }
            )

        # Generate extractive summary from chunks
        summary = extractive_summary_from_chunks(chunks) if chunks else ""  # type: ignore[arg-type]
        headings = extract_headings(chunks)  # type: ignore[arg-type]

        guide_data = {
            "id": guide_id,
            "name": frontmatter.name,
            "namespace": namespace,
            "tags": frontmatter.metadata.tags,
            "description": frontmatter.description,
            "source_type": frontmatter.metadata.type,
            "source_url": frontmatter.metadata.url,
            "file_path": file_path,
            "content_hash": content_hash,
            "indexed_at": now,
            "summary": summary,
            "headings": headings,
        }

        guides_table = self._get_or_create_table("guides", GuideSchema)
        guides_table.add([guide_data])

        if chunk_records:
            chunks_table = self._get_or_create_table("chunks", ChunkSchema)
            chunks_table.add(chunk_records)

    def update_last_indexed(self) -> None:
        """Update the last_indexed_at timestamp in metadata."""
        now = datetime.now(UTC).isoformat()

        if "_metadata" in self.db.list_tables().tables:
            table = self.db.open_table("_metadata")
            metadata_list = table.search().limit(1).to_pydantic(DatabaseMetadata)
            if metadata_list:
                metadata = metadata_list[0]
                # Update with new timestamp
                updated = DatabaseMetadata(
                    created_at=metadata.created_at,
                    last_indexed_at=now,
                    library_path=metadata.library_path,
                )
                self.db.drop_table("_metadata")
                new_table = self.db.create_table("_metadata", schema=DatabaseMetadata)
                new_table.add([updated])

    def get_guide_count(self) -> int:
        """Get number of guides in the database."""
        if "guides" not in self.db.list_tables().tables:
            return 0
        return int(self.db.open_table("guides").count_rows())

    def get_chunk_count(self) -> int:
        """Get number of chunks in the database."""
        if "chunks" not in self.db.list_tables().tables:
            return 0
        return int(self.db.open_table("chunks").count_rows())

    def create_fts_indexes(self) -> None:
        """
        Create full-text search indexes for hybrid search.

        Creates FTS indexes on:
        - chunks.heading_path - for BM25 boost on full heading breadcrumb
        - guides.headings - for BM25 boost on guide headings

        Uses stem=False for multilingual compatibility.
        """
        # FTS index on chunks.heading_path for keyword matching
        if "chunks" in self.db.list_tables().tables:
            chunks_table = self.db.open_table("chunks")
            chunks_table.create_fts_index(
                "heading_path",
                stem=False,  # No stemming for technical terms
                lower_case=True,
                ascii_folding=True,
                replace=True,
            )

        # FTS index on guides.headings for keyword matching
        if "guides" in self.db.list_tables().tables:
            guides_table = self.db.open_table("guides")
            guides_table.create_fts_index(
                "headings",
                stem=False,
                lower_case=True,
                ascii_folding=True,
                replace=True,
            )
